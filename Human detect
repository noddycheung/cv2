import cv2
import time
import numpy as np

classesFile = 'For YOLO/coco80.names'
classes = open(classesFile, 'r').read().splitlines()
confThreshold = 0.3

net = cv2.dnn.readNetFromDarknet('For YOLO/yolov3-320.cfg', 'For YOLO/yolov3-320.weights')
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

class_of_interest = 0

cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)

cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

time.sleep(1)

prev_boxes = []

while cap.isOpened():
    ret, frame = cap.read()
    height, width, ch = frame.shape

    blob = cv2.dnn.blobFromImage(frame, 1 / 255, (320, 320), (0, 0, 0), swapRB=True, crop=False)
    net.setInput(blob)

    outputs = net.forward(net.getUnconnectedOutLayersNames())
    boxes, confidences = [], []

    for output in outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if confidence > confThreshold and class_id == class_of_interest:
                center_x, center_y, w, h = map(int, detection[:4] * [width, height, width, height])
                x, y = center_x - w // 2, center_y - h // 2
                boxes.append([x, y, w, h])
                confidences.append(confidence)

    # Remove duplicate detections
    boxes, confidences = np.array(boxes), np.array(confidences)
    indexes = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, 0.4)
    if len(indexes) > 0:
        boxes, confidences = boxes[indexes.flatten()], confidences[indexes.flatten()]

    font, colors = cv2.FONT_HERSHEY_PLAIN, np.random.uniform(0, 255, size=(len(boxes), 3))

    if len(boxes) > 0:
        for i in range(len(boxes)):
            x, y, w, h = boxes[i]
            label, color = str(classes[class_of_interest]), colors[i]
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            cv2.putText(frame, f"{label}", (x, y + 20), font, 2, (255, 255, 255), 2)

    for x, y, w, h in boxes:
        if [x, y, w, h] not in prev_boxes:
            # sending coordinates to Arduino
            string = 'X{0:d}Y{1:d}'.format((x + w // 2), (y + h // 2))
            print(string)
            #ArduinoSerial.write(string.encode('utf-8'))
            # plot the center of the face
            cv2.circle(frame, (x + w // 2, y + h // 2), 2, (0, 255, 0), 2)
            # roi
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 3)
            prev_boxes.append([x, y, w, h])
    # squared region in the center of the screen
    cv2.rectangle(frame, (1280 // 2 - 30, 720 // 2 - 30),
                  (1280 // 2 + 30, 720 // 2 + 30),
                  (255, 255, 255), 3)

    # out.write(frame)
    cv2.imshow('img', frame)
    # cv2.imwrite('output_img.jpg',frame)
    '''for testing purpose
    read= str(ArduinoSerial.readline(ArduinoSerial.inWaiting()))
    time.sleep(0.05)
    print('data from arduino:'+read)
    '''

    if cv2.waitKey(10) & 0xFF == 27:
        break
cap.release()
cv2.destroyAllWindows()
